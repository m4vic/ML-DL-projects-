{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMif34YdWgrifG8ldZPDii2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m4vic/ML-models/blob/main/Models-from-scratch/svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czxQtaS1RAe7"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class svm():\n",
        "  def __init__(self, learning_rate, no_of_itr , C):\n",
        "    # C = error that we want to count , no_of_itr  mean how much time the model will run .\n",
        "\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.no_of_itr= no_of_itr\n",
        "    self.C = C\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "\n",
        "    # X = the features\n",
        "    # y = the label\n",
        "\n",
        "    # m --> no. of data points or no. of rows\n",
        "    # n --> no. of input features or no. colums\n",
        "    self.m , self.n = X.Shape    # in this by using the Shape function we transefer the Rows to M and column to N\n",
        "\n",
        "    # initating the weigts and bias value\n",
        "\n",
        "\n",
        "    self.w = np.zeros(self.n) # shape of the w is array of the vector ie n which is the no. of column\n",
        "    self.b = 0 # bias is  0\n",
        "    self.X = X # X is the feature\n",
        "    self.y = y # y is label\n",
        "\n",
        "\n",
        "\n",
        "    # gradiant descent for svm\n",
        "\n",
        "    # the model will go to the data as difined in no. of iteration\n",
        "    # each time it will update the weights and bias\n",
        "    for i in range(self.no_of_itr):\n",
        "      self.update_weights()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights(self, x, y_label, predicted_label):\n",
        "    # lebel encoding. the np.where tries to find the condition\n",
        "    # column 0 as -1 and 1 as 1\n",
        "    y_label = np.where(self.y <= 0, -1, 1)\n",
        "\n",
        "    # this is the gradiant descent if else part where if (y*(w*x-b) >=  1) else (y*(w*x-b)< 1)\n",
        "\n",
        "\n",
        "\n",
        "    for index , x_i in enumerate(self.X):\n",
        "      condition  =  y_label[index] * (np.dot(x_i, self.w) - self.b) >=1\n",
        "      # enumerate is the function which gives index as well as the value also\n",
        "      # y_label is the outcome column it will take the value\n",
        "      # x_i is the features value and we do dot function that convert vector to scaler\n",
        "      # w is the weights and b is bias\n",
        "      if (condition == True):\n",
        "        dw = 2*self.C*self.w\n",
        "        db  = 0\n",
        "\n",
        "\n",
        "      else\n",
        "\n",
        "        dw = 2 * self.C * self.w - np.dot(x_i , ylabel[index])\n",
        "        db = y_label[index]\n",
        "\n",
        "\n",
        "      self.w = self.w - self.learning_rate * dw # assiging the value w = w-l*dw\n",
        "      self.b = self.b - self.learning_rate * db # assiging the value b = b-l*db\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    output = np.dot(X, self.w) - self.b # the predict formula coded in python\n",
        "    # rounding the variable\n",
        "     # the output will not be - 1 or 1 or 0 it will be any positive no. or negative no.\n",
        "    predicted_labels = np.sign(output) # rounding the output using np.signs .\n",
        "\n",
        "    # np.signs devide the data into 1 and -1\n",
        "\n",
        "    y_hat = np.where(predicted_labels <= -1, 0, 1) # re changing the -1 to 0\n",
        "\n",
        "    return y_hat\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VGy7K3qSRGip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "298c3eb9-d931-4390-e7d1-360d0d0635b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-3-421e8db4b039>, line 61)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-421e8db4b039>\"\u001b[0;36m, line \u001b[0;32m61\u001b[0m\n\u001b[0;31m    else\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "inweTt-5E9Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcSYf9eHgEpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgYsPuoGgRek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}